{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation\n",
    "\n",
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic segmentation using the KITTI dataset, and can be done using three methods:\n",
    "- **Full-Convolutional Network [2014]** Uses a pretrained network, upsample using deconvolution, and have skip connections to improve coarseness of upsampling.\n",
    "- **SegNet [2015]** Encoder-Decoder architecture\n",
    "- **ResNet-DUC [2017]** Dense Upsampling and Hybrid Dilated convolution\n",
    "- To improve the quality of segmentation can use something resembling FlowNet with optical flow to improve the quality of segmentation wrt. ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## List all imports\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import os.path as path\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline \n",
    "\n",
    "repeat=0\n",
    "import helper\n",
    "from utils import tensorflow_check,load_vggmodel,model,optimizer,training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Datasets\n",
    "root='kitti_dataset/'\n",
    "training_dataset='kitti_dataset/training'\n",
    "testing_dataset='kitti_dataset/testing'\n",
    "vgg_path='vgg/'\n",
    "save_sessions='sessions/'\n",
    "output='output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "# Check Tensorflow installation\n",
    "print(\"Tensorflow Version: \",tf.__version__)\n",
    "tensorflow_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Defining Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters and variables\n",
    "image_shape=(160,576)\n",
    "num_classes=2\n",
    "learning_rate_value=1e-4\n",
    "keep_prob_value=0.65\n",
    "n_epochs=50\n",
    "batch_size=5\n",
    "Loss_summary=[]\n",
    "save_path='./tf-sessions-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating placeholders\n",
    "label=tf.placeholder(tf.float32,[None,image_shape[0],image_shape[1],num_classes])\n",
    "learning_rate=tf.placeholder(tf.float32)\n",
    "keep_prob=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG-16 model with skip-connections and an Adam Optimizer to minimize cross-entropy loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# def model(vgg_layer3,vgg_layer4,vgg_layer7,n_classes):\n",
    "#     # Encoder 1*1 convolutions\n",
    "#     layer_3=convolution_1x1(vgg_layer3,n_classes,'Convolution_layer3')\n",
    "#     layer_4=convolution_1x1(vgg_layer4,n_classes,'Convolution_layer4')\n",
    "#     layer_7=convolution_1x1(vgg_layer7,n_classes,'Convolution_layer7')\n",
    "    \n",
    "#     deconvolution_1=convolution_sampling(layer_7,n_classes,k_size=4,st_size=2,x_name='deconvolution_layer_1')\n",
    "#     skip_connection_1=tf.add(deconvolution_1,layer_4,name='deconvolution_layer_2')\n",
    "#     deconvolution_2=convolution_sampling(skip_connection_1,n_classes,k_size=4,st_size=2,x_name='deconvolution_layer_3')\n",
    "#     skip_connection_2=tf.add(deconvolution_2,layer_3,name='deconvolution_layer_4')\n",
    "#     output=convolution_sampling(skip_connection_2,k_size=16,st_size=8,x_name='deconvolution_output')\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def optimizer(layer,ground_truth,learning_rate,n_classes):\n",
    "    logits=tf.reshape(layer,(-1,n_classes))\n",
    "    labels=tf.reshape(ground_truth,(-1,n_classes)\n",
    "    # Cross entropy loss\n",
    "    cross_entropy_loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate)\n",
    "    train_operation=optimizer.minimizer(cross_entropy_loss)\n",
    "                     \n",
    "    return logits,cross_entropy_loss,train_operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting images batches\n",
      "Running Tensorflow session\n",
      "Loading pretrained VGG16 model\n",
      "INFO:tensorflow:Restoring parameters from b'vgg/variables/variables'\n",
      "Creating model with skip-layers and deconvolutions\n",
      "Running Adam Optimizer to minimize cross-entropy loss\n",
      "Global Variables initializer\n",
      "Training\n",
      "Epoch 1 of 50: Training Loss 1.1672073602676392\n",
      "Epoch 2 of 50: Training Loss 0.7990897297859192\n",
      "Epoch 3 of 50: Training Loss 0.7141979932785034\n",
      "Epoch 4 of 50: Training Loss 0.6754484176635742\n",
      "Epoch 5 of 50: Training Loss 0.6523394584655762\n",
      "Epoch 6 of 50: Training Loss 0.6155242919921875\n",
      "Epoch 7 of 50: Training Loss 0.5784335136413574\n",
      "Epoch 8 of 50: Training Loss 0.5534160733222961\n",
      "Epoch 9 of 50: Training Loss 0.4834023714065552\n",
      "Epoch 10 of 50: Training Loss 0.45666348934173584\n",
      "Epoch 11 of 50: Training Loss 0.3671443462371826\n",
      "Epoch 12 of 50: Training Loss 0.29985466599464417\n",
      "Epoch 13 of 50: Training Loss 0.222471222281456\n",
      "Epoch 14 of 50: Training Loss 0.22275103628635406\n",
      "Epoch 15 of 50: Training Loss 0.1755690574645996\n",
      "Epoch 16 of 50: Training Loss 0.21304535865783691\n",
      "Epoch 17 of 50: Training Loss 0.2588235139846802\n",
      "Epoch 18 of 50: Training Loss 0.23173873126506805\n",
      "Epoch 19 of 50: Training Loss 0.1588737517595291\n",
      "Epoch 20 of 50: Training Loss 0.1576651632785797\n",
      "Epoch 21 of 50: Training Loss 0.15700040757656097\n",
      "Epoch 22 of 50: Training Loss 0.15654537081718445\n",
      "Epoch 23 of 50: Training Loss 0.12747320532798767\n",
      "Epoch 24 of 50: Training Loss 0.11340539902448654\n",
      "Epoch 25 of 50: Training Loss 0.13129973411560059\n",
      "Epoch 26 of 50: Training Loss 0.0981871485710144\n",
      "Epoch 27 of 50: Training Loss 0.07874134182929993\n",
      "Epoch 28 of 50: Training Loss 0.10558455437421799\n",
      "Epoch 29 of 50: Training Loss 0.13037340342998505\n",
      "Epoch 30 of 50: Training Loss 0.06633264571428299\n",
      "Epoch 31 of 50: Training Loss 0.06325945258140564\n",
      "Epoch 32 of 50: Training Loss 0.06429514288902283\n",
      "Epoch 33 of 50: Training Loss 0.10803180932998657\n",
      "Epoch 34 of 50: Training Loss 0.10824012011289597\n",
      "Epoch 35 of 50: Training Loss 0.05582626536488533\n",
      "Epoch 36 of 50: Training Loss 0.08010753989219666\n",
      "Epoch 37 of 50: Training Loss 0.0709964781999588\n",
      "Epoch 38 of 50: Training Loss 0.06380517780780792\n",
      "Epoch 39 of 50: Training Loss 0.08520648628473282\n",
      "Epoch 40 of 50: Training Loss 0.0714850202202797\n",
      "Epoch 41 of 50: Training Loss 0.05894314497709274\n",
      "Epoch 42 of 50: Training Loss 0.06246836110949516\n",
      "Epoch 43 of 50: Training Loss 0.0525827556848526\n",
      "Epoch 44 of 50: Training Loss 0.04369542375206947\n",
      "Epoch 45 of 50: Training Loss 0.06703660637140274\n",
      "Epoch 46 of 50: Training Loss 0.10930075496435165\n",
      "Epoch 47 of 50: Training Loss 0.044008247554302216\n",
      "Epoch 48 of 50: Training Loss 0.03756853938102722\n",
      "Epoch 49 of 50: Training Loss 0.046213697642087936\n",
      "Epoch 50 of 50: Training Loss 0.03708655387163162\n"
     ]
    }
   ],
   "source": [
    "## Load pretrained VGG-16 model and dataset pretrained on ImageNet\n",
    "print(\"Getting images batches\")\n",
    "get_batches_fn=helper.gen_batch_function(training_dataset,image_shape)\n",
    "print(\"Running Tensorflow session\")\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    print(\"Loading pretrained VGG16 model\")\n",
    "    input_image,keep_prob,layer3,layer4,layer7=load_vggmodel(session,vgg_path)\n",
    "    print(\"Creating model with skip-layers and deconvolutions\")\n",
    "    output_layer=model(layer3,layer4,layer7,num_classes)\n",
    "    print(\"Running Adam Optimizer to minimize cross-entropy loss\")\n",
    "    logits,cross_entropy_loss,train_operation=optimizer(output_layer,label,learning_rate,num_classes)\n",
    "\n",
    "    print(\"Global Variables initializer\")\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver=tf.train.Saver()\n",
    "    print(\"Training\")\n",
    "    training(session,n_epochs,batch_size,get_batches_fn,train_operation,\n",
    "                 cross_entropy_loss,input_image,label,keep_prob,learning_rate,keep_prob_value,learning_rate_value)\n",
    "    saver.save(session,save_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(\"Saving inference data\")\n",
    "#     helper.save_inference_samples(output,root,session,image_shape,\n",
    "#                                   logits,keep_prob,input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
